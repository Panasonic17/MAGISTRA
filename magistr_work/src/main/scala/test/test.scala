//package test
//
//import http.HttpClient
//import org.apache.commons.csv.{CSVFormat, CSVRecord}
//import org.apache.spark.sql.SparkSession
//import org.apache.spark.sql.catalyst.ScalaReflection
//import org.apache.spark.sql.types._
//
//object test {
//
//
//  def main(args: Array[String]): Unit = {
//    //
//    //    val spark = SparkSession
//    //      .builder
//    //      .master("local[*]")
//    //      .appName("a")
//    //      .getOrCreate()
//    //
//            var tablename = "ahasnf"
//    //
//            val inputPath ="C:\\WORK_DIR\\NORTHORM\\tmp\\sparktest\\input\\" + tablename + ".csv"
//    //
//    //        val data = spark.read.option("header", "true").option("inferSchema", "true").option("delimiter", "\u001F").csv(inputPath)
//    //        println(data.schema)
//
////    val in = new Nothing(inputPath)
////    val records = CSVFormat.DEFAULT
////      .parse(in);
//
//
//
//  }
//}
